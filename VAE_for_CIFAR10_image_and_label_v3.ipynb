{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eca066f91ef34ce0850ddc9f0e7a39b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0687615a87ac4bcdaf8b5333e259aad2",
              "IPY_MODEL_d3cfa7bb05124005a9b29b85a710539f",
              "IPY_MODEL_e3727d1235eb42cebc3ae9690d234230"
            ],
            "layout": "IPY_MODEL_21998707930749808ef4064bec53c8e2"
          }
        },
        "0687615a87ac4bcdaf8b5333e259aad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d441f0a0f49247229b000114e0723cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_93613c2c5610449fbd63150eafc32651",
            "value": "Epoch 49: 100%"
          }
        },
        "d3cfa7bb05124005a9b29b85a710539f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee847b1b43e549eead7a4d15c33eba2f",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccb8c3004cef41bd9c930b1ba2109ab7",
            "value": 79
          }
        },
        "e3727d1235eb42cebc3ae9690d234230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e3d358a8bb04baaa6116d85b139c0ec",
            "placeholder": "​",
            "style": "IPY_MODEL_074e1f50c7c5437593457fbe7f120817",
            "value": " 79/79 [01:15&lt;00:00,  1.05it/s, loss=1.7e+03, v_num=0]"
          }
        },
        "21998707930749808ef4064bec53c8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d441f0a0f49247229b000114e0723cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93613c2c5610449fbd63150eafc32651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee847b1b43e549eead7a4d15c33eba2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb8c3004cef41bd9c930b1ba2109ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e3d358a8bb04baaa6116d85b139c0ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074e1f50c7c5437593457fbe7f120817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/TASI_ERAv2_S22/blob/main/VAE_for_CIFAR10_image_and_label_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue4hW0MtyAIm"
      },
      "source": [
        "%%capture\n",
        "! pip install pytorch-lightning\n",
        "# ! pip install pytorch-lightning-bolts\n",
        "! pip install git+https://github.com/PytorchLightning/lightning-bolts.git@master --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from pl_bolts.models.autoencoders.components import (\n",
        "    resnet18_decoder,\n",
        "    resnet18_encoder,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq5q7zvH6Os3",
        "outputId": "661a3f1a-bb78-4e2b-e0ee-1a548b315f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(pl.LightningModule):\n",
        "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32, num_classes=10, label_embedding_dim=50):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Initial conv layer to adjust input channels\n",
        "        # self.initial_conv = nn.Conv2d(1 + num_classes, 3, kernel_size=3, stride=1, padding=1)\n",
        "        self.initial_conv_block = nn.Sequential(\n",
        "                    nn.Conv2d(3 + num_classes, 3, kernel_size=(1, 1), padding=0, bias=False),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.BatchNorm2d(3),\n",
        "        )\n",
        "\n",
        "        # encoder, decoder\n",
        "        self.encoder = resnet18_encoder(first_conv=False, maxpool1=False)\n",
        "        self.decoder = resnet18_decoder(\n",
        "            latent_dim=latent_dim + label_embedding_dim,\n",
        "            input_height=input_height,\n",
        "            first_conv=False,\n",
        "            maxpool1=False\n",
        "        )\n",
        "\n",
        "        # label embedding\n",
        "        self.label_embedding = nn.Embedding(num_classes, label_embedding_dim)\n",
        "\n",
        "        # distribution parameters\n",
        "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
        "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
        "\n",
        "        # for the gaussian likelihood\n",
        "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "    def gaussian_likelihood(self, mean, logscale, sample):\n",
        "        scale = torch.exp(logscale)\n",
        "        dist = torch.distributions.Normal(mean, scale)\n",
        "        log_pxz = dist.log_prob(sample)\n",
        "        return log_pxz.sum(dim=(1, 2, 3))\n",
        "\n",
        "    def kl_divergence(self, z, mu, std):\n",
        "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        log_qzx = q.log_prob(z)\n",
        "        log_pz = p.log_prob(z)\n",
        "        kl = (log_qzx - log_pz).sum(-1)\n",
        "        return kl\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        # One-hot encode labels\n",
        "        labels_onehot = F.one_hot(labels, num_classes=self.hparams.num_classes).float()\n",
        "        labels_onehot = labels_onehot.unsqueeze(2).unsqueeze(3).expand(-1, -1, x.size(2), x.size(3))\n",
        "        x = torch.cat((x, labels_onehot), dim=1)  # batch_size x (embed_dim + num channels) x img_size x img_size\n",
        "        x = self.initial_conv_block(x) # convert to 3 channels as resnet encoder supports 3 channels\n",
        "        x_encoded = self.encoder(x)#.reshape(x.size(0), -1)\n",
        "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
        "        std = torch.exp(log_var / 2)\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        z = q.rsample()\n",
        "\n",
        "        # Embed labels for the decoder\n",
        "        labels_embedded = self.label_embedding(labels)\n",
        "        z = torch.cat((z, labels_embedded), dim=1)\n",
        "        x_hat = self.decoder(z)\n",
        "\n",
        "        return x_hat, mu, log_var\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, labels = batch\n",
        "        x_hat, mu, log_var = self(x, labels)\n",
        "\n",
        "        std = torch.exp(log_var / 2)\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        z = q.rsample()\n",
        "\n",
        "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
        "        kl = self.kl_divergence(z, mu, std)\n",
        "        elbo = (kl - recon_loss).mean()\n",
        "\n",
        "        self.log_dict({\n",
        "            'elbo': elbo,\n",
        "            'kl': kl.mean(),\n",
        "            'recon_loss': recon_loss.mean()\n",
        "        })\n",
        "\n",
        "        return elbo\n"
      ],
      "metadata": {
        "id": "PR4on6pNI_Gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1476ec69-0524-4ddf-dc28-59737ba1920b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg5bOMsDHGUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac5a6d9-9f2f-4211-e52c-0317767a334e"
      },
      "source": [
        "from pl_bolts.datamodules import CIFAR10DataModule\n",
        "cifar = CIFAR10DataModule('.', batch_size = 512)\n",
        "cifar.prepare_data()\n",
        "cifar.setup()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9207752.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937,
          "referenced_widgets": [
            "eca066f91ef34ce0850ddc9f0e7a39b8",
            "0687615a87ac4bcdaf8b5333e259aad2",
            "d3cfa7bb05124005a9b29b85a710539f",
            "e3727d1235eb42cebc3ae9690d234230",
            "21998707930749808ef4064bec53c8e2",
            "d441f0a0f49247229b000114e0723cd0",
            "93613c2c5610449fbd63150eafc32651",
            "ee847b1b43e549eead7a4d15c33eba2f",
            "ccb8c3004cef41bd9c930b1ba2109ab7",
            "2e3d358a8bb04baaa6116d85b139c0ec",
            "074e1f50c7c5437593457fbe7f120817"
          ]
        },
        "id": "MvBo844ZHQhF",
        "outputId": "6658c58c-6d71-4142-fcdb-0914c896b71d"
      },
      "source": [
        "pl.seed_everything(1234)\n",
        "epochs = 50\n",
        "vae = VAE()\n",
        "trainer = pl.Trainer(devices=1, accelerator=\"gpu\", max_epochs=epochs, enable_progress_bar=True)\n",
        "trainer.fit(vae, cifar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 1234\n",
            "<ipython-input-3-f418cf61387c>:16: UnderReviewWarning: The feature resnet18_encoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.encoder = resnet18_encoder(first_conv=False, maxpool1=False)\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:326: UnderReviewWarning: The feature ResNetEncoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return ResNetEncoder(EncoderBlock, [2, 2, 2, 2], first_conv, maxpool1)\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:230: UnderReviewWarning: The feature EncoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  layers.append(block(self.inplanes, planes, stride, downsample))\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:56: UnderReviewWarning: The feature conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.conv1 = conv3x3(inplanes, planes, stride)\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:225: UnderReviewWarning: The feature conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  conv1x1(self.inplanes, planes * block.expansion, stride),\n",
            "<ipython-input-3-f418cf61387c>:17: UnderReviewWarning: The feature resnet18_decoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.decoder = resnet18_decoder(\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:331: UnderReviewWarning: The feature ResNetDecoder is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return ResNetDecoder(DecoderBlock, [2, 2, 2, 2], latent_dim, input_height, first_conv, maxpool1)\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:294: UnderReviewWarning: The feature resize_conv1x1 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  resize_conv1x1(self.inplanes, planes * block.expansion, scale),\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:45: UnderReviewWarning: The feature Interpolate is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return nn.Sequential(Interpolate(scale_factor=scale), conv1x1(in_planes, out_planes))\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:299: UnderReviewWarning: The feature DecoderBlock is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  layers.append(block(self.inplanes, planes, scale, upsample))\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/autoencoders/components.py:129: UnderReviewWarning: The feature resize_conv3x3 is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.conv1 = resize_conv3x3(inplanes, inplanes)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:106: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name               | Type          | Params\n",
            "-----------------------------------------------------\n",
            "0 | initial_conv_block | Sequential    | 45    \n",
            "1 | encoder            | ResNetEncoder | 11.2 M\n",
            "2 | decoder            | ResNetDecoder | 9.0 M \n",
            "3 | label_embedding    | Embedding     | 500   \n",
            "4 | fc_mu              | Linear        | 131 K \n",
            "5 | fc_var             | Linear        | 131 K \n",
            "-----------------------------------------------------\n",
            "20.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "20.5 M    Total params\n",
            "81.869    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eca066f91ef34ce0850ddc9f0e7a39b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spIp7mogliDI"
      },
      "source": [
        "## Plot an image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = cifar.val_dataloader()\n",
        "x, y = next(iter(test))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5Mw3XGcG8QM",
        "outputId": "7bf82364-616e-4e95-f450-0b2de59066b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([512, 3, 32, 32]), torch.Size([512]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_preds = 25\n",
        "y_t = y[0:num_preds]\n",
        "print(y_t)\n",
        "# Generate a random permutation of indices\n",
        "indices = torch.randperm(y.numel())\n",
        "shuffled_y = y[indices][0:num_preds]\n",
        "shuffled_y"
      ],
      "metadata": {
        "id": "1awuPeEWWw0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da92dbea-5067-4393-8b54-c3b1a551877a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 6, 6, 9, 1, 1, 8, 9, 4, 7, 0, 5, 7, 2, 2, 1, 7, 6, 2, 8, 8, 2, 2, 5,\n",
            "        7])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 3, 1, 2, 8, 3, 8, 2, 8, 3, 2, 4, 5, 0, 0, 6, 6, 3, 4, 1, 3, 0, 2, 1,\n",
              "        9])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    pred , mu, log_var = vae(x[0:num_preds].to(vae.device), shuffled_y.to(vae.device))\n",
        "\n",
        "print('mu:', mu.shape)\n",
        "print('log_var:', log_var.shape)\n",
        "\n",
        "# SAMPLE Z from Q(Z|x)\n",
        "std = torch.exp(log_var / 2)\n",
        "q = torch.distributions.Normal(mu, std)\n",
        "z = q.rsample()\n",
        "\n",
        "print('z shape:', z.shape)\n",
        "print('pred size:', pred.size())"
      ],
      "metadata": {
        "id": "1Z_2uiKIHPtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03aed684-e605-43eb-9ba0-c9b625997375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu: torch.Size([25, 256])\n",
            "log_var: torch.Size([25, 256])\n",
            "z shape: torch.Size([25, 256])\n",
            "pred size: torch.Size([25, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj91rMEcXxco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "5240bf83-7617-4afb-fe0f-1edd1a1e35d1"
      },
      "source": [
        "from matplotlib.pyplot import imshow, figure\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
        "figure(figsize=(8, 3), dpi=300)\n",
        "\n",
        "pred = pred.cpu()\n",
        "# UNDO DATA NORMALIZATION\n",
        "normalize = cifar10_normalization()\n",
        "mean, std = np.array(normalize.mean), np.array(normalize.std)\n",
        "img = make_grid(pred,nrow = 5).permute(1, 2, 0).numpy() * std + mean\n",
        "\n",
        "# PLOT IMAGES\n",
        "imshow(img);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cifar10_normalization() takes 0 positional arguments but 1 was given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-eb3fa85f985c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# UNDO DATA NORMALIZATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cifar10_normalization() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x900 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labeled images"
      ],
      "metadata": {
        "id": "IVvx71ovS0uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "class_labels = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "def plot_image(images, target_labels, pred_labels = None, rows = 5, cols = 5,\n",
        "               img_size=(5,5), font_size = 7):\n",
        "    figure = plt.figure(figsize=img_size)\n",
        "    for index in range(cols * rows):\n",
        "        plt.subplot(rows, cols, index+1)\n",
        "        if pred_labels is not None:\n",
        "            plt.title(f'image: {class_labels[target_labels[index]]}\\nlabel: {class_labels[pred_labels[index]]}',\n",
        "                  fontsize = font_size)\n",
        "        else:\n",
        "            plt.title(f'image: {class_labels[target_labels[index]]}', fontsize = font_size)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(images[index])\n",
        "    figure.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FWtXxS9XfG8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = pred.permute(0, 2, 3, 1).numpy() * std + mean\n",
        "plot_image(imgs, target_labels = y_t, pred_labels = shuffled_y)"
      ],
      "metadata": {
        "id": "8JHtJ30xRLe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}